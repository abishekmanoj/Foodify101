{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5893bcf8-5603-4f25-a626-3bb5c43afcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19779ec8-c487-4cda-8315-adfd58e67619",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup Device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388f2f3c-b2ca-45d7-8124-7c578f5e8791",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get data\n",
    "from modules.data import create_datasets, create_dataloaders\n",
    "\n",
    "data_transforms = torchvision.models.ResNet50_Weights.DEFAULT.transforms()\n",
    "root = 'data'\n",
    "\n",
    "train_data, test_data, class_names = create_datasets(dataset=torchvision.datasets.Food101, download_path=root, transform=data_transforms)\n",
    "train_dataloader, test_dataloader = create_dataloaders(train_data=train_data, test_data=test_data, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ac5857-5e12-4279-a487-aa2d98d3465a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Model\n",
    "from torch import nn\n",
    "from modules.utils import load_model\n",
    "\n",
    "weights = torchvision.models.ResNet50_Weights.DEFAULT\n",
    "model = torchvision.models.resnet50(weights=weights).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf1f26b-db94-4302-b994-ca8df1cfb52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Phase 1 - Initial Training \n",
    "# --------------------------------------\n",
    "# - Only the final fully-connected (fc) layer is unfrozen; all base layers are frozen.\n",
    "# - Trains the classifier head on top of pretrained ImageNet features.\n",
    "# - Used learning rate: 1e-3\n",
    "# - No scheduler used.\n",
    "# - Training for 15 epochs.\n",
    "\n",
    "from modules.engine import train\n",
    "\n",
    "# Freeze all the layers\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# UnFreeze the fc layer\n",
    "model.fc = nn.Linear(in_features=2048, out_features=len(class_names), bias=True).to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "tp1_optimizer = torch.optim.Adam(params=filter(lambda p: p.requires_grad, model.parameters()), lr=1e-3)\n",
    "\n",
    "tp1_results = train(model=model, train_dataloader=train_dataloader, test_dataloader=test_dataloader, epochs=15, \n",
    "                loss_fn=loss_fn, optimizer=tp1_optimizer, device=device, scheduler=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d2f6a9-7759-47bb-a993-1cb55a63350c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.utils import save_model\n",
    "\n",
    "save_path = 'models/phase1.pth'\n",
    "save_model(model=model, target_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98794831-69f8-451f-90bb-8f0f452dea23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Phase 2 - Fine-Tuning High-Level Features\n",
    "# -----------------------------------------\n",
    "# - Unfroze 'layer4' along with the 'fc' layer; all earlier layers remain frozen.\n",
    "# - Modify the fc layer to have dropout.\n",
    "# - Trains high-level ResNet features specific to the Food101 dataset.\n",
    "# - Used learning rate: 1e-4\n",
    "# - No scheduler used.\n",
    "# - Training for 15 epochs.\n",
    "# - Goal: Allow deeper parts of the model to learn domain-specific representations.\n",
    "\n",
    "# UnFreeze the fc layer and layer 4\n",
    "for name, param in model.named_parameters():\n",
    "    if \"layer4\" in name or \"fc\" in name:\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "\n",
    "# Modify the fc layer\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Dropout(p=0.3, inplace=True),\n",
    "    nn.Linear(in_features=2048, out_features=len(class_names), bias=True)\n",
    ").to(device)\n",
    "\n",
    "tp2_optimizer = torch.optim.Adam(params=filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)\n",
    "\n",
    "tp2_results = train(model=model, train_dataloader=train_dataloader, test_dataloader=test_dataloader, epochs=15, \n",
    "                loss_fn=loss_fn, optimizer=tp2_optimizer, device=device, scheduler=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc0065b-34c9-4e4a-957c-db90ce274a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'models/phase2.pth'\n",
    "save_model(model=model, target_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807a6f9e-3171-484f-8619-7779d47be1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 3 - Progressive Fine-Tuning with Layer-Specific Learning Rates\n",
    "# --------------------------------------------------------------------\n",
    "# - Unfroze 'layer3', 'layer4', and 'fc' layers.\n",
    "# - Used layer-specific learning rates:\n",
    "#     - layer3: 1e-6\n",
    "#     - layer4: 1e-5\n",
    "#     - fc:     1e-4\n",
    "# - Introduced StepLR scheduler to gradually reduce learning rate every 5 epochs.\n",
    "# - Goal: Fine-tune both mid- and high-level feature layers for maximum accuracy while avoiding overfitting.\n",
    "\n",
    "# UnFreeze the fc layer and layer 3, 4\n",
    "for name, param in model.named_parameters():\n",
    "    if any(layer in name for layer in [\"layer3\", \"layer4\", \"fc\"]):\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "tp3_optimizer = torch.optim.AdamW([\n",
    "    {\"params\": model.layer3.parameters(), \"lr\": 1e-6},\n",
    "    {\"params\": model.layer4.parameters(), \"lr\": 1e-5},\n",
    "    {\"params\": model.fc.parameters(), \"lr\": 1e-4}\n",
    "], weight_decay=1e-4)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(tp3_optimizer, step_size=5, gamma=0.5)\n",
    "\n",
    "tp3_results = train(model=model, train_dataloader=train_dataloader, test_dataloader=test_dataloader, epochs=20, \n",
    "                loss_fn=loss_fn, optimizer=tp3_optimizer, device=device, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f40d32-efbb-47e9-8720-dad96178b263",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'models/foodify_101.pth'\n",
    "save_model(model=model, target_path=save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
